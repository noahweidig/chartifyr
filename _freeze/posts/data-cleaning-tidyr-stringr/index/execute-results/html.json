{
  "hash": "f383c62a4c405fed5364bdeacaa654f2",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Data Cleaning in the Real World\"\nsubtitle: \"From messy CSVs to analysis-ready tables with tidyr and stringr\"\nexecute:\n  warning: false\nauthor: \"Noah Weidig\"\ndate: \"2025-02-22\"\ncategories: [code, tidyverse]\nimage: \"images/tidyr.jpg\"\ndescription: \"Learn how to reshape, split, and clean messy data using tidyr and stringr — pivoting, separating columns, pattern matching, and handling common gotchas.\"\ntoc: true\ntoc-depth: 2\ncode-fold: show\n---\n\n\n\n[![Artwork by \\@allison_horst](images/tidyr.jpg)](https://twitter.com/allison_horst)\n\nYou know the drill. Someone hands you a spreadsheet with columns like `cases_2019`, `cases_2020`, `cases_2021`, values crammed into single cells, and mysterious `NA`s scattered everywhere. Before you can analyze anything, you need to *clean* it. This is where `tidyr` and `stringr` come in — and where most of your time as a data analyst actually goes.\n\nThis tutorial builds directly on [Basics of dplyr](../dplyr-basics/index.qmd). If you're comfortable with `filter()`, `mutate()`, and the pipe, you're ready.\n\n# Setup\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n```\n:::\n\n\n\nWe'll use two built-in datasets throughout this post:\n\n- **`who2`** — World Health Organization tuberculosis data (comes with `tidyr`). Wide, messy, and realistic.\n- **`starwars`** — Character data from the Star Wars films (comes with `dplyr`). Has strings to clean and list-columns to untangle.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwho2\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 7,240 × 58\n   country      year sp_m_014 sp_m_1524 sp_m_2534 sp_m_3544 sp_m_4554 sp_m_5564\n   <chr>       <dbl>    <dbl>     <dbl>     <dbl>     <dbl>     <dbl>     <dbl>\n 1 Afghanistan  1980       NA        NA        NA        NA        NA        NA\n 2 Afghanistan  1981       NA        NA        NA        NA        NA        NA\n 3 Afghanistan  1982       NA        NA        NA        NA        NA        NA\n 4 Afghanistan  1983       NA        NA        NA        NA        NA        NA\n 5 Afghanistan  1984       NA        NA        NA        NA        NA        NA\n 6 Afghanistan  1985       NA        NA        NA        NA        NA        NA\n 7 Afghanistan  1986       NA        NA        NA        NA        NA        NA\n 8 Afghanistan  1987       NA        NA        NA        NA        NA        NA\n 9 Afghanistan  1988       NA        NA        NA        NA        NA        NA\n10 Afghanistan  1989       NA        NA        NA        NA        NA        NA\n# ℹ 7,230 more rows\n# ℹ 50 more variables: sp_m_65 <dbl>, sp_f_014 <dbl>, sp_f_1524 <dbl>,\n#   sp_f_2534 <dbl>, sp_f_3544 <dbl>, sp_f_4554 <dbl>, sp_f_5564 <dbl>,\n#   sp_f_65 <dbl>, sn_m_014 <dbl>, sn_m_1524 <dbl>, sn_m_2534 <dbl>,\n#   sn_m_3544 <dbl>, sn_m_4554 <dbl>, sn_m_5564 <dbl>, sn_m_65 <dbl>,\n#   sn_f_014 <dbl>, sn_f_1524 <dbl>, sn_f_2534 <dbl>, sn_f_3544 <dbl>,\n#   sn_f_4554 <dbl>, sn_f_5564 <dbl>, sn_f_65 <dbl>, ep_m_014 <dbl>, …\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nstarwars |> select(name, height, mass, skin_color, homeworld)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 87 × 5\n   name               height  mass skin_color  homeworld\n   <chr>               <int> <dbl> <chr>       <chr>    \n 1 Luke Skywalker        172    77 fair        Tatooine \n 2 C-3PO                 167    75 gold        Tatooine \n 3 R2-D2                  96    32 white, blue Naboo    \n 4 Darth Vader           202   136 white       Tatooine \n 5 Leia Organa           150    49 light       Alderaan \n 6 Owen Lars             178   120 light       Tatooine \n 7 Beru Whitesun Lars    165    75 light       Tatooine \n 8 R5-D4                  97    32 white, red  Tatooine \n 9 Biggs Darklighter     183    84 light       Tatooine \n10 Obi-Wan Kenobi        182    77 fair        Stewjon  \n# ℹ 77 more rows\n```\n\n\n:::\n:::\n\n\n\n# Reshaping with pivot_longer()\n\nThe most common mess you'll run into is data that's *wide* when it should be *long*. The `who2` dataset is a textbook example — it has separate columns for every combination of diagnosis method, sex, and age group.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwho2 |> colnames() |> head(20)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n [1] \"country\"   \"year\"      \"sp_m_014\"  \"sp_m_1524\" \"sp_m_2534\" \"sp_m_3544\"\n [7] \"sp_m_4554\" \"sp_m_5564\" \"sp_m_65\"   \"sp_f_014\"  \"sp_f_1524\" \"sp_f_2534\"\n[13] \"sp_f_3544\" \"sp_f_4554\" \"sp_f_5564\" \"sp_f_65\"   \"sn_m_014\"  \"sn_m_1524\"\n[19] \"sn_m_2534\" \"sn_m_3544\"\n```\n\n\n:::\n:::\n\n\n\nEach of those `sp_m_014`, `sp_f_1524` columns encodes three variables in a single column name. That's not tidy. Let's pivot.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwho_long <- who2 |>\n  pivot_longer(\n    cols = !c(country, year),\n    names_to = \"category\",\n    values_to = \"count\",\n    values_drop_na = TRUE\n  )\n\nwho_long\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 76,046 × 4\n   country      year category  count\n   <chr>       <dbl> <chr>     <dbl>\n 1 Afghanistan  1997 sp_m_014      0\n 2 Afghanistan  1997 sp_m_1524    10\n 3 Afghanistan  1997 sp_m_2534     6\n 4 Afghanistan  1997 sp_m_3544     3\n 5 Afghanistan  1997 sp_m_4554     5\n 6 Afghanistan  1997 sp_m_5564     2\n 7 Afghanistan  1997 sp_m_65       0\n 8 Afghanistan  1997 sp_f_014      5\n 9 Afghanistan  1997 sp_f_1524    38\n10 Afghanistan  1997 sp_f_2534    36\n# ℹ 76,036 more rows\n```\n\n\n:::\n:::\n\n\n\nThe `values_drop_na = TRUE` argument quietly drops all the rows where count is `NA`. Without it, you'd end up with thousands of empty rows — a common gotcha that balloons your data for no reason.\n\n## Pivoting with names_sep\n\nThose `category` values still pack three pieces of information into one string. We can split them during the pivot itself.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwho_tidy <- who2 |>\n  pivot_longer(\n    cols = !c(country, year),\n    names_to = c(\"diagnosis\", \"sex\", \"age_group\"),\n    names_sep = \"_\",\n    values_to = \"count\",\n    values_drop_na = TRUE\n  )\n\nwho_tidy\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 76,046 × 6\n   country      year diagnosis sex   age_group count\n   <chr>       <dbl> <chr>     <chr> <chr>     <dbl>\n 1 Afghanistan  1997 sp        m     014           0\n 2 Afghanistan  1997 sp        m     1524         10\n 3 Afghanistan  1997 sp        m     2534          6\n 4 Afghanistan  1997 sp        m     3544          3\n 5 Afghanistan  1997 sp        m     4554          5\n 6 Afghanistan  1997 sp        m     5564          2\n 7 Afghanistan  1997 sp        m     65            0\n 8 Afghanistan  1997 sp        f     014           5\n 9 Afghanistan  1997 sp        f     1524         38\n10 Afghanistan  1997 sp        f     2534         36\n# ℹ 76,036 more rows\n```\n\n\n:::\n:::\n\n\n\nOne call and we went from a 56-column mess to a clean, long-format table with clearly named variables. That's the power of `pivot_longer()`.\n\n# Going wide with pivot_wider()\n\nSometimes you need the opposite — spreading long data into a wider format for summary tables or specific analyses. Let's say we want a quick comparison table of total TB cases by diagnosis method and sex.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwho_tidy |>\n  group_by(diagnosis, sex) |>\n  summarize(total = sum(count), .groups = \"drop\") |>\n  pivot_wider(\n    names_from = sex,\n    values_from = total\n  )\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 4 × 3\n  diagnosis        f        m\n  <chr>        <dbl>    <dbl>\n1 ep          941880  1044299\n2 rel        1201596  2018976\n3 sn         2439139  3840388\n4 sp        11324409 20586831\n```\n\n\n:::\n:::\n\n\n\n`pivot_wider()` is the inverse of `pivot_longer()`. You'll reach for it less often, but it's essential for creating cross-tabulations and reporting tables.\n\n# Splitting and combining columns\n\n## separate_wider_delim()\n\nSometimes a single column contains multiple values separated by a delimiter. Let's manufacture a quick example to see `separate_wider_delim()` in action.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmessy_locations <- tibble(\n  id = 1:4,\n  location = c(\"USA-New York\", \"CAN-Toronto\", \"GBR-London\", \"AUS-Sydney\")\n)\n\nmessy_locations |>\n  separate_wider_delim(\n    location,\n    delim = \"-\",\n    names = c(\"country_code\", \"city\")\n  )\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 4 × 3\n     id country_code city    \n  <int> <chr>        <chr>   \n1     1 USA          New York\n2     2 CAN          Toronto \n3     3 GBR          London  \n4     4 AUS          Sydney  \n```\n\n\n:::\n:::\n\n\n\nThis cleanly splits one column into two. If the number of pieces isn't consistent across rows, use `too_few` and `too_many` to control the behavior:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntricky <- tibble(\n  id = 1:3,\n  value = c(\"A-B-C\", \"D-E\", \"F-G-H-I\")\n)\n\ntricky |>\n  separate_wider_delim(\n    value,\n    delim = \"-\",\n    names = c(\"first\", \"second\", \"third\"),\n    too_few = \"align_start\",\n    too_many = \"merge\"\n  )\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 × 4\n     id first second third\n  <int> <chr> <chr>  <chr>\n1     1 A     B      C    \n2     2 D     E      <NA> \n3     3 F     G      H-I  \n```\n\n\n:::\n:::\n\n\n\nThe `too_few = \"align_start\"` fills missing pieces with `NA` from the right. The `too_many = \"merge\"` lumps extra pieces into the last column. This keeps your pipeline from crashing on messy, inconsistent data.\n\n## unite()\n\n`unite()` is the reverse — gluing columns together.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwho_tidy |>\n  unite(\"demographic\", sex, age_group, sep = \"_\") |>\n  select(country, year, diagnosis, demographic, count) |>\n  head()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 5\n  country      year diagnosis demographic count\n  <chr>       <dbl> <chr>     <chr>       <dbl>\n1 Afghanistan  1997 sp        m_014           0\n2 Afghanistan  1997 sp        m_1524         10\n3 Afghanistan  1997 sp        m_2534          6\n4 Afghanistan  1997 sp        m_3544          3\n5 Afghanistan  1997 sp        m_4554          5\n6 Afghanistan  1997 sp        m_5564          2\n```\n\n\n:::\n:::\n\n\n\nThis is handy when you need to create an interaction label for plotting or joining.\n\n# String manipulation with stringr\n\nReal-world data is full of inconsistent text. The `stringr` package gives you a consistent set of functions (all starting with `str_`) for detecting, extracting, and replacing patterns.\n\n## str_detect() — finding patterns\n\n`str_detect()` returns `TRUE` or `FALSE`, making it perfect inside `filter()`.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Which Star Wars characters have \"Skywalker\" in their name?\nstarwars |>\n  filter(str_detect(name, \"Skywalker\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 × 14\n  name      height  mass hair_color skin_color eye_color birth_year sex   gender\n  <chr>      <int> <dbl> <chr>      <chr>      <chr>          <dbl> <chr> <chr> \n1 Luke Sky…    172    77 blond      fair       blue            19   male  mascu…\n2 Anakin S…    188    84 blond      fair       blue            41.9 male  mascu…\n3 Shmi Sky…    163    NA black      fair       brown           72   fema… femin…\n# ℹ 5 more variables: homeworld <chr>, species <chr>, films <list>,\n#   vehicles <list>, starships <list>\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Find characters with multiple skin colors (contain a comma)\nstarwars |>\n  filter(str_detect(skin_color, \",\")) |>\n  select(name, skin_color)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 14 × 2\n   name                  skin_color         \n   <chr>                 <chr>              \n 1 R2-D2                 white, blue        \n 2 R5-D4                 white, red         \n 3 Jabba Desilijic Tiure green-tan, brown   \n 4 Watto                 blue, grey         \n 5 Sebulba               grey, red          \n 6 Ratts Tyerel          grey, blue         \n 7 Dud Bolt              blue, grey         \n 8 Gasgano               white, blue        \n 9 Ben Quadinaros        grey, green, yellow\n10 Zam Wesell            fair, green, yellow\n11 R4-P17                silver, red        \n12 Wat Tambor            green, grey        \n13 Shaak Ti              red, blue, white   \n14 Grievous              brown, white       \n```\n\n\n:::\n:::\n\n\n\n## str_replace() and str_replace_all()\n\n`str_replace()` swaps the first match; `str_replace_all()` swaps every match. This is essential for cleaning up inconsistent labels.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstarwars |>\n  mutate(skin_color = str_replace_all(skin_color, \", \", \"/\")) |>\n  filter(str_detect(skin_color, \"/\")) |>\n  select(name, skin_color)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 14 × 2\n   name                  skin_color       \n   <chr>                 <chr>            \n 1 R2-D2                 white/blue       \n 2 R5-D4                 white/red        \n 3 Jabba Desilijic Tiure green-tan/brown  \n 4 Watto                 blue/grey        \n 5 Sebulba               grey/red         \n 6 Ratts Tyerel          grey/blue        \n 7 Dud Bolt              blue/grey        \n 8 Gasgano               white/blue       \n 9 Ben Quadinaros        grey/green/yellow\n10 Zam Wesell            fair/green/yellow\n11 R4-P17                silver/red       \n12 Wat Tambor            green/grey       \n13 Shaak Ti              red/blue/white   \n14 Grievous              brown/white      \n```\n\n\n:::\n:::\n\n\n\nA common use case: standardizing messy category labels.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nraw_labels <- c(\"United States\", \"united states\", \"US\", \"U.S.\", \"usa\")\n\nraw_labels |>\n  str_to_lower() |>\n  str_replace_all(c(\n    \"^us$\"      = \"united states\",\n    \"^u\\\\.s\\\\.$\" = \"united states\",\n    \"^usa$\"      = \"united states\"\n  ))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"united states\" \"united states\" \"united states\" \"united states\"\n[5] \"united states\"\n```\n\n\n:::\n:::\n\n\n\n## str_extract() — pulling out pieces\n\n`str_extract()` grabs the first matching portion of a string. Let's pull the numeric age boundaries from our cleaned WHO data.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwho_tidy |>\n  mutate(\n    age_start = str_extract(age_group, \"^\\\\d+\") |> as.integer()\n  ) |>\n  distinct(age_group, age_start) |>\n  arrange(age_start)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 7 × 2\n  age_group age_start\n  <chr>         <int>\n1 014              14\n2 65               65\n3 1524           1524\n4 2534           2534\n5 3544           3544\n6 4554           4554\n7 5564           5564\n```\n\n\n:::\n:::\n\n\n\n## str_trim() and str_squish()\n\nWhitespace is the silent killer of joins and group-bys. Two rows that *look* identical can fail to match because one has a trailing space.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmessy_names <- c(\"  Alice \", \"Bob\", \" Charlie  \", \"  Alice\")\n\n# str_trim removes leading/trailing whitespace\nstr_trim(messy_names)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"Alice\"   \"Bob\"     \"Charlie\" \"Alice\"  \n```\n\n\n:::\n\n```{.r .cell-code}\n# str_squish also collapses internal whitespace\nstr_squish(\"  too   many   spaces  \")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"too many spaces\"\n```\n\n\n:::\n:::\n\n\n\nAlways trim your strings before joining or grouping. This one habit will save you hours of debugging.\n\n# Common gotchas\n\n## Factor explosions\n\nWhen you read a CSV, character columns sometimes get read as factors. This means `levels()` bakes in the exact set of unique values. If you then `filter()` down to a subset, the unused levels stick around as ghosts — inflating your legend in plots, adding empty groups in summaries, and generally causing confusion.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Simulate the problem\nspecies_factor <- factor(c(\"cat\", \"dog\", \"bird\", \"cat\", \"dog\"))\nfiltered <- species_factor[species_factor != \"bird\"]\n\n# \"bird\" is gone from the data but still in the levels\nlevels(filtered)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"bird\" \"cat\"  \"dog\" \n```\n\n\n:::\n\n```{.r .cell-code}\n# Fix: drop unused levels\nlevels(droplevels(filtered))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"cat\" \"dog\"\n```\n\n\n:::\n:::\n\n\n\nThe lesson: use `droplevels()` after filtering factor data, or better yet, keep text as character columns with `stringsAsFactors = FALSE` (the default since R 4.0) and convert to factors only when you need explicit ordering.\n\n## NA handling\n\nMissing values propagate silently. Any arithmetic with `NA` returns `NA`. Any comparison with `NA` returns `NA`. This means `filter(x == NA)` never returns rows — use `is.na()` instead.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# This returns nothing — NA == NA is NA, not TRUE\nstarwars |>\n  filter(mass == NA) |>\n  nrow()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0\n```\n\n\n:::\n\n```{.r .cell-code}\n# This is what you actually want\nstarwars |>\n  filter(is.na(mass)) |>\n  select(name, mass) |>\n  head()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 2\n  name            mass\n  <chr>          <dbl>\n1 Wilhuff Tarkin    NA\n2 Mon Mothma        NA\n3 Arvel Crynyd      NA\n4 Finis Valorum     NA\n5 Rugor Nass        NA\n6 Ric Olié          NA\n```\n\n\n:::\n:::\n\n\n\nFor summaries, always pass `na.rm = TRUE`.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Without na.rm — returns NA\nstarwars |>\n  summarize(avg_height = mean(height))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 1\n  avg_height\n       <dbl>\n1         NA\n```\n\n\n:::\n\n```{.r .cell-code}\n# With na.rm — returns the actual mean\nstarwars |>\n  summarize(avg_height = mean(height, na.rm = TRUE))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 1\n  avg_height\n       <dbl>\n1       175.\n```\n\n\n:::\n:::\n\n\n\nIf you want to replace `NA`s with a default value, use `replace_na()` from tidyr.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstarwars |>\n  mutate(hair_color = replace_na(hair_color, \"unknown\")) |>\n  count(hair_color, sort = TRUE) |>\n  head()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 2\n  hair_color     n\n  <chr>      <int>\n1 none          38\n2 brown         18\n3 black         13\n4 unknown        5\n5 white          4\n6 blond          3\n```\n\n\n:::\n:::\n\n\n\n## Duplicate rows\n\nBefore any analysis, always check for duplicates. `distinct()` keeps unique rows, and `get_dupes()` from the `janitor` package can identify which rows are repeated. Here's the tidyverse approach:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwho_tidy |>\n  group_by(country, year, diagnosis, sex, age_group) |>\n  filter(n() > 1) |>\n  nrow()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0\n```\n\n\n:::\n:::\n\n\n\nZero duplicates — good. When you do find them, decide whether to keep the first, last, or aggregate.\n\n# Putting it all together\n\nLet's chain everything into a real pipeline. Starting from the raw `who2` data, we'll clean, reshape, and summarize in one shot.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwho2 |>\n  # Reshape: wide to long, splitting column names\n  pivot_longer(\n    cols = !c(country, year),\n    names_to = c(\"diagnosis\", \"sex\", \"age_group\"),\n    names_sep = \"_\",\n    values_to = \"count\",\n    values_drop_na = TRUE\n  ) |>\n  # Clean: standardize sex labels\n  mutate(\n    sex = str_replace_all(sex, c(\"m\" = \"male\", \"f\" = \"female\")),\n    age_start = str_extract(age_group, \"^\\\\d+\") |> as.integer()\n  ) |>\n  # Filter: focus on recent data\n  filter(year >= 2010) |>\n  # Summarize: total cases by country and sex\n  group_by(country, sex) |>\n  summarize(total_cases = sum(count), .groups = \"drop\") |>\n  # Reshape: make a comparison table\n  pivot_wider(names_from = sex, values_from = total_cases) |>\n  # Sort: highest total burden first\n  mutate(total = male + female) |>\n  arrange(desc(total)) |>\n  head(10)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 10 × 4\n   country                                female    male   total\n   <chr>                                   <dbl>   <dbl>   <dbl>\n 1 China                                 1059090 2381098 3440188\n 2 India                                  585702 1316362 1902064\n 3 South Africa                           593847  669632 1263479\n 4 Indonesia                              530997  727340 1258337\n 5 Bangladesh                             243335  399146  642481\n 6 Pakistan                               206403  206493  412896\n 7 Russian Federation                     121867  273245  395112\n 8 Philippines                            111062  262920  373982\n 9 Democratic People's Republic of Korea  130943  211636  342579\n10 Kenya                                  137336  188480  325816\n```\n\n\n:::\n:::\n\n\n\nThat's eight operations piped together, and every step reads like a sentence. This kind of pipeline is what your daily R work will actually look like.\n\n# Quick reference\n\n| Function | Package | What it does |\n|----------|---------|-------------|\n| `pivot_longer()` | tidyr | Reshape wide data to long format |\n| `pivot_wider()` | tidyr | Reshape long data to wide format |\n| `separate_wider_delim()` | tidyr | Split one column into many by delimiter |\n| `unite()` | tidyr | Combine multiple columns into one |\n| `replace_na()` | tidyr | Replace `NA` with a specified value |\n| `str_detect()` | stringr | Test if a pattern exists in a string |\n| `str_replace()` | stringr | Replace first match of a pattern |\n| `str_replace_all()` | stringr | Replace all matches of a pattern |\n| `str_extract()` | stringr | Pull out the first match of a pattern |\n| `str_trim()` | stringr | Remove leading/trailing whitespace |\n| `str_squish()` | stringr | Trim + collapse internal whitespace |\n\nThis is the unglamorous core of data analysis — the cleaning that happens before any chart or model. Master these tools and you'll spend less time fighting your data and more time learning from it.\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}